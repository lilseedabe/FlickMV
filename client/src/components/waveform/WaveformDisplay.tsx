import React, { useRef, useEffect, useState, useCallback } from 'react';
import { motion } from 'framer-motion';
import type { AudioTrack } from '@/types';

interface WaveformDisplayProps {
  audioTrack: AudioTrack;
  width: number;
  height: number;
  startTime: number;
  duration: number;
  zoom: number;
  color?: string;
  onWaveformClick?: (time: number) => void;
  showBeats?: boolean;
  className?: string;
}

interface WaveformData {
  peaks: Float32Array;
  length: number;
  sampleRate: number;
}

const WaveformDisplay: React.FC<WaveformDisplayProps> = ({
  audioTrack,
  width,
  height,
  startTime,
  duration,
  zoom,
  color = '#3b82f6',
  onWaveformClick,
  showBeats = true,
  className = ''
}) => {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [waveformData, setWaveformData] = useState<WaveformData | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  // æ³¢å½¢ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ - æ”¹è‰¯ç‰ˆï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰
  const generateWaveformData = useCallback(async (audioUrl: string): Promise<WaveformData | null> => {
    // æ—¢ã«æ³¢å½¢ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    if (waveformData) {
      return waveformData;
    }
    
    try {
      setIsLoading(true);
      setError(null);

      let arrayBuffer: ArrayBuffer;
      
      // AudioTrackã«originalFileãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
      if (audioTrack.originalFile) {
        try {
          arrayBuffer = await audioTrack.originalFile.arrayBuffer();
        } catch (fileError) {
          console.warn('Original file processing failed, falling back to URL', fileError);
          // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: URLã‚’ä½¿ç”¨
          const response = await fetch(audioUrl);
          if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
          }
          arrayBuffer = await response.arrayBuffer();
        }
      } else {
        // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: URLã‚’ä½¿ç”¨
        const response = await fetch(audioUrl);
        if (!response.ok) {
          throw new Error(`HTTP error! status: ${response.status}`);
        }
        arrayBuffer = await response.arrayBuffer();
      }
      
      // AudioContextã§éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
      const audioContext = new AudioContext();
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
      
      // ãƒ”ãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
      const rawData = audioBuffer.getChannelData(0); // ãƒ¢ãƒãƒ©ãƒ«ã¾ãŸã¯å·¦ãƒãƒ£ãƒ³ãƒãƒ«
      const blockSize = Math.floor(rawData.length / (width * 2)); // 1ãƒ”ã‚¯ã‚»ãƒ«ã‚ãŸã‚Šã®ã‚µãƒ³ãƒ—ãƒ«æ•°
      const peaks = new Float32Array(width * 2);
      
      for (let i = 0; i < width * 2; i++) {
        const start = i * blockSize;
        const end = Math.min(start + blockSize, rawData.length);
        
        let min = 0;
        let max = 0;
        
        for (let j = start; j < end; j++) {
          const sample = rawData[j];
          if (sample > max) max = sample;
          if (sample < min) min = sample;
        }
        
        peaks[i] = i % 2 === 0 ? max : min;
      }
      
      const result = {
        peaks,
        length: audioBuffer.length,
        sampleRate: audioBuffer.sampleRate
      };
      
      // AudioContextã‚’ã‚¯ãƒ­ãƒ¼ã‚º
      audioContext.close();
      
      return result;
    } catch (err) {
      console.error('æ³¢å½¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼:', err);
      setError('æ³¢å½¢ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ');
      return null;
    } finally {
      setIsLoading(false);
    }
  }, [width, audioTrack, waveformData]);

  // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›´ã•ã‚ŒãŸæ™‚ã«æ³¢å½¢ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
  useEffect(() => {
    let isMounted = true;
    
    const loadWaveformData = async () => {
      if (audioTrack.url && !waveformData) {
        console.log('ğŸ“ æ³¢å½¢ç”Ÿæˆ: åŸå§‹Fileã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½¿ç”¨');
        try {
          const data = await generateWaveformData(audioTrack.url);
          if (isMounted) {
            setWaveformData(data);
          }
        } catch (error) {
          console.error('Waveform data loading failed:', error);
          if (isMounted) {
            setError('æ³¢å½¢ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ');
          }
        }
      }
    };
    
    loadWaveformData();
    
    return () => {
      isMounted = false;
    };
  }, [audioTrack.url, audioTrack.id, generateWaveformData]);

  // æ³¢å½¢ã‚’æç”»
  const drawWaveform = useCallback(() => {
    const canvas = canvasRef.current;
    if (!canvas || !waveformData) return;

    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    // ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚’ã‚¯ãƒªã‚¢
    ctx.clearRect(0, 0, width, height);
    
    // èƒŒæ™¯ã‚’æç”»
    ctx.fillStyle = 'rgba(15, 23, 42, 0.3)'; // dark-900 with opacity
    ctx.fillRect(0, 0, width, height);
    
    // ä¸­å¤®ç·šã‚’æç”»
    ctx.strokeStyle = 'rgba(148, 163, 184, 0.3)'; // slate-400 with opacity
    ctx.lineWidth = 1;
    ctx.beginPath();
    ctx.moveTo(0, height / 2);
    ctx.lineTo(width, height / 2);
    ctx.stroke();

    // æ³¢å½¢ã‚’æç”»
    ctx.fillStyle = color;
    ctx.strokeStyle = color;
    ctx.lineWidth = 1;

    const centerY = height / 2;
    const scale = (height / 2) * 0.9; // 90%ã®é«˜ã•ã‚’ä½¿ç”¨

    for (let i = 0; i < width * 2; i += 2) {
      const x = i / 2;
      const maxPeak = waveformData.peaks[i] * scale;
      const minPeak = waveformData.peaks[i + 1] * scale;
      
      // æ­£ã®æ³¢å½¢ï¼ˆä¸ŠåŠåˆ†ï¼‰
      if (maxPeak > 0) {
        ctx.fillRect(x, centerY - maxPeak, 1, maxPeak);
      }
      
      // è² ã®æ³¢å½¢ï¼ˆä¸‹åŠåˆ†ï¼‰
      if (minPeak < 0) {
        ctx.fillRect(x, centerY, 1, Math.abs(minPeak));
      }
    }

    // ãƒ“ãƒ¼ãƒˆãƒãƒ¼ã‚«ãƒ¼ã‚’æç”»
    if (showBeats && audioTrack.beats && audioTrack.beats.length > 0) {
      ctx.strokeStyle = 'rgba(251, 191, 36, 0.7)'; // amber-400 with opacity
      ctx.lineWidth = 1;
      
      audioTrack.beats.forEach(beatTime => {
        // ãƒ“ãƒ¼ãƒˆæ™‚é–“ãŒã“ã®è¡¨ç¤ºç¯„å›²å†…ã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if (beatTime >= startTime && beatTime <= startTime + duration) {
          const x = ((beatTime - startTime) / duration) * width;
          
          ctx.beginPath();
          ctx.moveTo(x, 0);
          ctx.lineTo(x, height);
          ctx.stroke();
        }
      });
    }

    // BPMãƒãƒ¼ã‚«ãƒ¼ã‚’æç”»ï¼ˆ4/4æ‹å­æƒ³å®šï¼‰
    if (audioTrack.bpm && audioTrack.bpm > 0) {
      const beatsPerSecond = audioTrack.bpm / 60;
      const beatInterval = 1 / beatsPerSecond;
      
      ctx.strokeStyle = 'rgba(239, 68, 68, 0.4)'; // red-500 with opacity
      ctx.lineWidth = 2;
      
      // å°ç¯€ç·šï¼ˆ4æ‹å­ã”ã¨ï¼‰
      for (let i = 0; i * beatInterval * 4 < duration; i++) {
        const measureTime = startTime + (i * beatInterval * 4);
        if (measureTime >= startTime && measureTime <= startTime + duration) {
          const x = ((measureTime - startTime) / duration) * width;
          
          ctx.beginPath();
          ctx.moveTo(x, 0);
          ctx.lineTo(x, height);
          ctx.stroke();
        }
      }
    }

    // ç¾åœ¨æ™‚é–“ã®ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    // ã“ã‚Œã¯è¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‹ã‚‰æ¸¡ã•ã‚Œã‚‹å ´åˆã«æç”»ã•ã‚Œã‚‹
  }, [waveformData, width, height, color, showBeats, audioTrack.beats, audioTrack.bpm, startTime, duration]);

  // æ³¢å½¢ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ã‚µã‚¤ã‚ºãŒå¤‰æ›´ã•ã‚ŒãŸæ™‚ã«å†æç”»
  useEffect(() => {
    drawWaveform();
  }, [drawWaveform]);

  // ã‚¯ãƒªãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
  const handleClick = useCallback((e: React.MouseEvent<HTMLCanvasElement>) => {
    if (!onWaveformClick) return;
    
    const canvas = canvasRef.current;
    if (!canvas) return;
    
    const rect = canvas.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const clickTime = startTime + (x / width) * duration;
    
    onWaveformClick(clickTime);
  }, [onWaveformClick, startTime, duration, width]);

  if (error) {
    return (
      <div 
        className={`flex items-center justify-center bg-red-500/10 border border-red-500/30 ${className}`}
        style={{ width, height }}
      >
        <span className="text-xs text-red-400">{error}</span>
      </div>
    );
  }

  return (
    <div className={`relative ${className}`} style={{ width, height }}>
      {isLoading && (
        <div 
          className="absolute inset-0 flex items-center justify-center bg-dark-800/50"
          style={{ width, height }}
        >
          <motion.div
            animate={{ rotate: 360 }}
            transition={{ duration: 1, repeat: Infinity, ease: "linear" }}
            className="w-4 h-4 border-2 border-blue-500 border-t-transparent rounded-full"
          />
        </div>
      )}
      
      <canvas
        ref={canvasRef}
        width={width}
        height={height}
        className="cursor-pointer hover:opacity-80 transition-opacity"
        onClick={handleClick}
        style={{ 
          width: `${width}px`, 
          height: `${height}px`,
          display: 'block'
        }}
      />
      
      {/* BPMæƒ…å ±ã®è¡¨ç¤º */}
      {audioTrack.bpm && (
        <div className="absolute top-1 right-1 bg-dark-900/80 text-xs text-amber-400 px-2 py-1 rounded">
          {audioTrack.bpm} BPM
        </div>
      )}
      
      {/* éŸ³å£°æƒ…å ±ã®ãƒ„ãƒ¼ãƒ«ãƒãƒƒãƒ— */}
      <div className="absolute bottom-1 left-1 bg-dark-900/80 text-xs text-slate-400 px-2 py-1 rounded">
        {audioTrack.name || 'Audio Track'}
      </div>
    </div>
  );
};

export default WaveformDisplay;
